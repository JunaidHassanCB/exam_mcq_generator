{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction"
      ],
      "metadata": {
        "id": "Krv9LtD10hV0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Title: Exam MCQ Generator"
      ],
      "metadata": {
        "id": "NdYnWlds0jwO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Installs"
      ],
      "metadata": {
        "id": "5hZMS8Bt0y_7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsGNHKnc0RxY",
        "outputId": "81555230-8ad1-4b78-db43-405aa1549c92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.0/163.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.3/803.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.5/215.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q python-dotenv\n",
        "\n",
        "!pip install -q langchain_experimental\n",
        "!pip install -q langchain\n",
        "\n",
        "!pip install -q openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pydantic"
      ],
      "metadata": {
        "id": "1Yx1gXrn01rT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "um-apBad03iv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "Fa6Q5e8V02S-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Source"
      ],
      "metadata": {
        "id": "pE6jPUrZ0652"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnv-pYxs06eg",
        "outputId": "72f1f698-6df6-40ec-c9d3-716e21400425"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_text_file(path):\n",
        "  with open(path, 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "  return text"
      ],
      "metadata": {
        "id": "jGhEuJEr1huL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts_path = '/content/drive/MyDrive/datasets/exam_mcq_generator/texts'\n",
        "\n",
        "text_path_01 = os.path.join(texts_path, '01.txt')\n",
        "text_01 = read_text_file(text_path_01)\n",
        "\n",
        "text_path_02 = os.path.join(texts_path, '02.txt')\n",
        "text_02 = read_text_file(text_path_02)\n",
        "\n",
        "text_path_03 = os.path.join(texts_path, '03.txt')\n",
        "text_03 = read_text_file(text_path_03)\n",
        "\n",
        "text_path_04 = os.path.join(texts_path, '04.txt')\n",
        "text_04 = read_text_file(text_path_04)\n",
        "\n",
        "text_path_05 = os.path.join(texts_path, '05.txt')\n",
        "text_05 = read_text_file(text_path_05)"
      ],
      "metadata": {
        "id": "UilQwGRH1Q3S"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Env"
      ],
      "metadata": {
        "id": "MvKQFU1u0_5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env_path = '/content/drive/MyDrive/credentials/data-analytics-demo/.env'"
      ],
      "metadata": {
        "id": "7kCLrM3G1EDq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "load_dotenv(env_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw6Tsu9B1GxJ",
        "outputId": "8fc6ee38-db15-48b0-cb06-d6779d809495"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_PALM_API_KEY = os.environ['GOOGLE_PALM_API_KEY']\n",
        "HUGGINGFACE_API_KEY = os.environ['HUGGINGFACE_API_KEY']\n",
        "OPEN_AI_API_KEY = os.environ['OPEN_AI_API_KEY']\n",
        "\n",
        "# GOOGLE_PALM_API_KEY, HUGGINGFACE_API_KEY, OPEN_AI_API_KEY"
      ],
      "metadata": {
        "id": "5UQeEMjW1H0h"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "enhDeSzG1zSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class MCQModel(BaseModel):\n",
        "  question: str = Field(description=\"This is the question text\")\n",
        "  options: list[str] = Field(description=\"This is a list of multiple choices or options avalible\")\n",
        "  correct_option: str = Field(description=\"This is the correct choice or option\")"
      ],
      "metadata": {
        "id": "YrgDBQoi10RG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MCQListModel(BaseModel):\n",
        "  mcq_list: list[MCQModel] = Field(description=\"A list of multiple choice questions\")"
      ],
      "metadata": {
        "id": "aJudkLVv4DoL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import PydanticOutputParser\n",
        "\n",
        "pydantic_parser = PydanticOutputParser(pydantic_object=MCQListModel)\n",
        "\n",
        "format_instructions = pydantic_parser.get_format_instructions()\n",
        "\n",
        "print(format_instructions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgOsKVWI13I-",
        "outputId": "9e3a1d6c-fb54-4fdc-9370-9341f102c06d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"properties\": {\"mcq_list\": {\"title\": \"Mcq List\", \"description\": \"A list of multiple choice questions\", \"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/MCQModel\"}}}, \"required\": [\"mcq_list\"], \"definitions\": {\"MCQModel\": {\"title\": \"MCQModel\", \"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"description\": \"This is the question text\", \"type\": \"string\"}, \"options\": {\"title\": \"Options\", \"description\": \"This is a list of multiple choices or options avalible\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}, \"correct_option\": {\"title\": \"Correct Option\", \"description\": \"This is the correct choice or option\", \"type\": \"string\"}}, \"required\": [\"question\", \"options\", \"correct_option\"]}}}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "langchain_llm = ChatOpenAI(openai_api_key=OPEN_AI_API_KEY, model_name=\"gpt-3.5-turbo-0613\", verbose=False,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1V31rQV1_kL",
        "outputId": "d07a325b-3a4a-4a83-8c7f-055a599e2913"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:115: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.ChatOpenAI instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = (\n",
        "    \"Following are blocks of text picked at random from a document:\"\n",
        "    \"\\n{texts}\"\n",
        "    \"\\nGenerate {n} non-repeating multiple choice questions along with their respective correct options from this text\"\n",
        "    \"\\nDo not use any outside information\"\n",
        "    \"\\n{format_instructions}\"\n",
        ")"
      ],
      "metadata": {
        "id": "8W1XZIeU2Dv6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = ChatPromptTemplate.from_template(prompt)\n",
        "\n",
        "prompt_template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cne6dkur2FAj",
        "outputId": "ed7774a7-3a04-4b87-fb6c-8682b2d45257"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['format_instructions', 'n', 'texts'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['format_instructions', 'n', 'texts'], template='Following are blocks of text picked at random from a document:\\n{texts}\\nGenerate {n} non-repeating multiple choice questions along with their respective correct options from this text\\nDo not use any outside information\\n{format_instructions}'))])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain = LLMChain(llm=langchain_llm, prompt=prompt_template, output_key=\"result\")"
      ],
      "metadata": {
        "id": "P8STiiBE2HWK"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_docs(text, chunk_size=500, chunk_overlap=0):\n",
        "  \"\"\"\n",
        "  note:\n",
        "    * When chunk_overlap=0, it will try not cut sentences, which is good for out case\n",
        "  \"\"\"\n",
        "  text_splitter = CharacterTextSplitter(\n",
        "      separator=\"\\n\",\n",
        "      chunk_size=chunk_size,\n",
        "      chunk_overlap=chunk_overlap,\n",
        "      length_function=len,\n",
        "      is_separator_regex=False,\n",
        "  )\n",
        "\n",
        "  docs = text_splitter.create_documents([text])\n",
        "\n",
        "  return docs"
      ],
      "metadata": {
        "id": "TWNgfVom2QxM"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.callbacks import get_openai_callback as get_langchain_openai_callback\n",
        "\n",
        "import random\n",
        "\n",
        "def get_exam(text, n=3):\n",
        "  \"\"\"\n",
        "  validation: total_docs <= n\n",
        "  \"\"\"\n",
        "\n",
        "  docs = get_docs(text)\n",
        "\n",
        "  if n > len(docs):\n",
        "    raise ValueError(f\"Too many questions specified, must be less then {len(docs)+1}\")\n",
        "\n",
        "  rand_docs = random.sample(docs, n)\n",
        "\n",
        "  texts = \"\".join([f\"Text Block {i+1}:\\n{doc.page_content}\\n\" for i, doc in enumerate(rand_docs)])\n",
        "\n",
        "  with get_langchain_openai_callback() as cb_langchain:\n",
        "    response = llm_chain.invoke({\"texts\": texts, \"n\": n, \"format_instructions\": format_instructions})\n",
        "\n",
        "  return {\"mcqs_parsed\": MCQListModel.parse_raw(response['result']).mcq_list, 'cb_langchain': cb_langchain}\n",
        "\n",
        "# get_exam(text_01)"
      ],
      "metadata": {
        "id": "L6F9-YwF5jdr"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing"
      ],
      "metadata": {
        "id": "LI9LhfUU507E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_exam(exam):\n",
        "\n",
        "  for i in exam['mcqs_parsed']:\n",
        "\n",
        "    print(f\"question: {i.question}\\n\")\n",
        "\n",
        "    for index, j in enumerate(i.options):\n",
        "      print(f\"{index+1}. {j}\")\n",
        "\n",
        "    print(f\"\\ncorrect: {i.correct_option}\\n\\n\")\n",
        "\n",
        "  print(exam['cb_langchain'])"
      ],
      "metadata": {
        "id": "vR4UOyPh9Tqb"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exam_01 = get_exam(text_01, n=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "o7fer6WsCBKl",
        "outputId": "af325b70-55f6-4ee9-c132-67ed42a7164f"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 509, which is longer than the specified 500\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Too many questions specified, must be less then 8",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-117-146eb441e5f9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexam_01\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_exam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-113-ddf7c28d0051>\u001b[0m in \u001b[0;36mget_exam\u001b[0;34m(text, n)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Too many questions specified, must be less then {len(docs)+1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mrand_docs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Too many questions specified, must be less then 8"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exam_01 = get_exam(text_01, n=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yglnLo5u50Vb",
        "outputId": "2ee7e4cb-b284-498f-8f04-c263c7132d24"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 509, which is longer than the specified 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_exam(exam_01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oo-hLcQx7sn7",
        "outputId": "6f8754e7-1333-4968-c02e-6b19fac33822"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question: What did Seraphina discover about the archipelago?\n",
            "\n",
            "1. It was home to mythical creatures\n",
            "2. It held the key to a realm between reality and dreams\n",
            "3. It was a place of lost civilizations\n",
            "4. It had boundaries of time and space intertwined\n",
            "\n",
            "correct: It held the key to a realm between reality and dreams\n",
            "\n",
            "\n",
            "question: What was the undercurrent that stirred within Seraphina's soul?\n",
            "\n",
            "1. Restlessness\n",
            "2. Adventure\n",
            "3. Curiosity\n",
            "4. Uncertainty\n",
            "\n",
            "correct: Restlessness\n",
            "\n",
            "\n",
            "question: What did Seraphina find half-buried in the sand?\n",
            "\n",
            "1. An ancient artifact\n",
            "2. A glowing stone\n",
            "3. A treasure chest\n",
            "4. A map\n",
            "\n",
            "correct: An ancient artifact\n",
            "\n",
            "\n",
            "question: What did Seraphina embark on a journey to unravel?\n",
            "\n",
            "1. The mysteries hidden within the ancient map\n",
            "2. The secrets of the archipelago\n",
            "3. Her own destiny\n",
            "4. The enigmatic landmarks\n",
            "\n",
            "correct: The mysteries hidden within the ancient map\n",
            "\n",
            "\n",
            "question: What did Seraphina become after her journey?\n",
            "\n",
            "1. A curious villager\n",
            "2. A guardian of realms\n",
            "3. A legendary figure\n",
            "4. A resident of Eldridge Haven\n",
            "\n",
            "correct: A guardian of realms\n",
            "\n",
            "\n",
            "Tokens Used: 1210\n",
            "\tPrompt Tokens: 851\n",
            "\tCompletion Tokens: 359\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.0019945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exam_02 = get_exam(text_02, n=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1IfHfV8-Mro",
        "outputId": "72f6aad9-c1b5-44c9-f0b8-89676f781d22"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 520, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 609, which is longer than the specified 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_exam(exam_02)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnmZ1dIK_4NJ",
        "outputId": "7501275c-2cb4-4f80-fdf9-64d2e3096298"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question: What were some of the ethical considerations surrounding SynthEra?\n",
            "\n",
            "1. Privacy and security\n",
            "2. Cost and availability\n",
            "3. Physical limitations\n",
            "4. Environmental impact\n",
            "\n",
            "correct: Privacy and security\n",
            "\n",
            "\n",
            "question: In which sectors did SynthEra have a significant impact?\n",
            "\n",
            "1. Agriculture and construction\n",
            "2. Medicine, education, and entertainment\n",
            "3. Finance and law\n",
            "4. Transportation and logistics\n",
            "\n",
            "correct: Medicine, education, and entertainment\n",
            "\n",
            "\n",
            "question: What was one of the key abilities provided by SynthEra?\n",
            "\n",
            "1. Telepathic communication\n",
            "2. Time travel\n",
            "3. Instantaneous teleportation\n",
            "4. Interacting with augmented reality\n",
            "\n",
            "correct: Interacting with augmented reality\n",
            "\n",
            "\n",
            "question: How did SynthEra establish a connection between the human brain and digital information?\n",
            "\n",
            "1. Through physical wires\n",
            "2. By using quantum technology\n",
            "3. Via advanced neurostimulation algorithms\n",
            "4. By implanting microchips in the brain\n",
            "\n",
            "correct: Via advanced neurostimulation algorithms\n",
            "\n",
            "\n",
            "question: What did SynthEra represent in the history of technology?\n",
            "\n",
            "1. A failure of human innovation\n",
            "2. A regression in technological advancements\n",
            "3. A testament to humanity's pursuit of innovation\n",
            "4. An unnecessary invention\n",
            "\n",
            "correct: A testament to humanity's pursuit of innovation\n",
            "\n",
            "\n",
            "Tokens Used: 1145\n",
            "\tPrompt Tokens: 777\n",
            "\tCompletion Tokens: 368\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.0019015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exam_03 = get_exam(text_03, n=5)"
      ],
      "metadata": {
        "id": "FVUrKbiY_uik"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_exam(exam_03)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIRQ_H5O_5Rq",
        "outputId": "078931bc-aae0-4f17-cec0-7865cb15fc6b"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question: What is the Collatz conjecture?\n",
            "\n",
            "1. A puzzle that has defied resolution for decades\n",
            "2. A mathematical theorem proven by Lothar Collatz\n",
            "3. A sequence that eventually reaches the cycle of 4, 2, 1\n",
            "4. A problem in number theory\n",
            "5. A puzzle simple enough for amateurs to grasp\n",
            "\n",
            "correct: A sequence that eventually reaches the cycle of 4, 2, 1\n",
            "\n",
            "\n",
            "question: Who proposed the Collatz conjecture?\n",
            "\n",
            "1. A group of scholars and amateurs\n",
            "2. Lothar Collatz\n",
            "3. German mathematicians\n",
            "4. Mathematicians exploring the unknown\n",
            "5. The mid-20th century intellectuals\n",
            "\n",
            "correct: Lothar Collatz\n",
            "\n",
            "\n",
            "question: What does the resolution of the Collatz conjecture promise?\n",
            "\n",
            "1. A solution to a mathematical puzzle\n",
            "2. A deeper understanding of the beauty of numbers\n",
            "3. A testament to the allure of the unknown\n",
            "4. A boundless exploration of infinite realms\n",
            "5. All of the above\n",
            "\n",
            "correct: All of the above\n",
            "\n",
            "\n",
            "question: What is the allure of the Collatz conjecture?\n",
            "\n",
            "1. Its simplicity that belies its depth\n",
            "2. The mysteries within number theory\n",
            "3. The enduring nature of the problem\n",
            "4. The dance of numbers\n",
            "5. Amateurs' ability to grasp it\n",
            "\n",
            "correct: Its simplicity that belies its depth\n",
            "\n",
            "\n",
            "question: How do mathematicians approach the Collatz conjecture?\n",
            "\n",
            "1. With an innate curiosity\n",
            "2. Undeterred by the obstinacy of the problem\n",
            "3. Diving into its depths\n",
            "4. Driven by the pursuit of knowledge\n",
            "5. All of the above\n",
            "\n",
            "correct: All of the above\n",
            "\n",
            "\n",
            "Tokens Used: 1261\n",
            "\tPrompt Tokens: 807\n",
            "\tCompletion Tokens: 454\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.0021185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exam_04 = get_exam(text_04, n=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSen-fHg_u9K",
        "outputId": "e689e5f7-0c2b-42a2-a052-65dfa64e158a"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 567, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 531, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 577, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 516, which is longer than the specified 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_exam(exam_04)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21Uzx3-p_6kC",
        "outputId": "e3273393-81e3-4600-b8f8-c7ce89b1ad46"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question: What is the aesthetic allure of poetry?\n",
            "\n",
            "1. Its ability to distill intricate emotions into a few carefully chosen words\n",
            "2. Its capacity to evoke profound verities\n",
            "3. Its manifestation in sundry configurations and idioms\n",
            "4. Its nuance in syllabic configurations and rhythmic resonances\n",
            "\n",
            "correct: Its ability to distill intricate emotions into a few carefully chosen words\n",
            "\n",
            "\n",
            "question: What does poetry constitute?\n",
            "\n",
            "1. A medium for the poet's oration\n",
            "2. A testament to the boundless potentiality of words\n",
            "3. A tapestry of allegorical impressions\n",
            "4. A convolution of lexical cadence\n",
            "\n",
            "correct: A testament to the boundless potentiality of words\n",
            "\n",
            "\n",
            "question: What does poetry endure as?\n",
            "\n",
            "1. An enigmatic manifestation\n",
            "2. An everlasting testimonial\n",
            "3. A contrivance of language\n",
            "4. A convolution of lexical cadence\n",
            "\n",
            "correct: An everlasting testimonial\n",
            "\n",
            "\n",
            "question: What does the nuanced choreography of syllabic configurations and rhythmic resonances enable poets to do?\n",
            "\n",
            "1. Forge connections betwixt disparate hearts and intellects\n",
            "2. Metamorphose prosaic verbiage into an intricate mosaic of expressive profundity\n",
            "3. Transcend the conventional confines of mundane discourse\n",
            "4. Wield a contrivance of language that begets an ethereal symphony\n",
            "\n",
            "correct: Metamorphose prosaic verbiage into an intricate mosaic of expressive profundity\n",
            "\n",
            "\n",
            "question: What do poets do within the nebulous realms of metaphorical articulation?\n",
            "\n",
            "1. Wield a contrivance of language that begets an ethereal symphony\n",
            "2. Meander the elusive shades of human sentiment\n",
            "3. Forge connections betwixt disparate hearts and intellects\n",
            "4. Manifest an enigmatic convolution of lexical cadence\n",
            "\n",
            "correct: Wield a contrivance of language that begets an ethereal symphony\n",
            "\n",
            "\n",
            "Tokens Used: 1337\n",
            "\tPrompt Tokens: 848\n",
            "\tCompletion Tokens: 489\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.00225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exam_05 = get_exam(text_05, n=5)"
      ],
      "metadata": {
        "id": "FNBbpIx3_vQi"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_exam(exam_05)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8w_fLRB2_7wS",
        "outputId": "d5a1fbe4-3746-44e0-910c-1966b7b6c1b7"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question: What are researchers currently focusing on in LLMs?\n",
            "\n",
            "1. Refining the models and addressing ethical concerns\n",
            "2. Developing rule-based systems\n",
            "3. Utilizing transformer architectures\n",
            "4. Translating Russian sentences into English\n",
            "\n",
            "correct: Refining the models and addressing ethical concerns\n",
            "\n",
            "\n",
            "question: What were the limitations of early rule-based systems in natural language processing?\n",
            "\n",
            "1. They struggled with the ambiguity and complexity of language\n",
            "2. They were constrained by limited computational power\n",
            "3. They lacked the ability to consider contextual information\n",
            "4. They failed to achieve true linguistic nuance\n",
            "\n",
            "correct: They struggled with the ambiguity and complexity of language\n",
            "\n",
            "\n",
            "question: Which model revolutionized natural language processing?\n",
            "\n",
            "1. LLMs\n",
            "2. Rule-based systems\n",
            "3. Transformer architectures\n",
            "4. Georgetown-IBM experiment\n",
            "\n",
            "correct: Transformer architectures\n",
            "\n",
            "\n",
            "question: What was the outcome of the Georgetown-IBM experiment in 1954?\n",
            "\n",
            "1. Successful translation of Russian sentences into English\n",
            "2. True linguistic nuance achieved\n",
            "3. Limited computational power overcome\n",
            "4. Partial understanding of human language\n",
            "\n",
            "correct: Partial understanding of human language\n",
            "\n",
            "\n",
            "question: What were the early endeavors in computational linguistics focused on?\n",
            "\n",
            "1. Understanding and generating human-like language\n",
            "2. Developing LLMs\n",
            "3. Improving rule-based systems\n",
            "4. Advancing transformer architectures\n",
            "\n",
            "correct: Understanding and generating human-like language\n",
            "\n",
            "\n",
            "Tokens Used: 1118\n",
            "\tPrompt Tokens: 733\n",
            "\tCompletion Tokens: 385\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.0018695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AIZO_U_H_9Uo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}