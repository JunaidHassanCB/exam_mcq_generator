{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction"
      ],
      "metadata": {
        "id": "Krv9LtD10hV0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Title: Exam MCQ Generator"
      ],
      "metadata": {
        "id": "NdYnWlds0jwO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Installs"
      ],
      "metadata": {
        "id": "5hZMS8Bt0y_7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsGNHKnc0RxY",
        "outputId": "ec28685f-8249-426b-b25f-bdae4695ed9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.0/163.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.3/803.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.5/215.5 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q python-dotenv\n",
        "\n",
        "!pip install -q langchain_experimental\n",
        "!pip install -q langchain\n",
        "\n",
        "!pip install -q openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pydantic"
      ],
      "metadata": {
        "id": "1Yx1gXrn01rT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "um-apBad03iv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "Fa6Q5e8V02S-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Source"
      ],
      "metadata": {
        "id": "pE6jPUrZ0652"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnv-pYxs06eg",
        "outputId": "da19115c-5387-4105-bcba-8d30799b4a3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_text_file(path):\n",
        "  with open(path, 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "  return text"
      ],
      "metadata": {
        "id": "jGhEuJEr1huL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts_path = '/content/drive/MyDrive/datasets/exam_mcq_generator/texts'\n",
        "\n",
        "text_path_01 = os.path.join(texts_path, '01.txt')\n",
        "text_01 = read_text_file(text_path_01)\n",
        "\n",
        "text_path_02 = os.path.join(texts_path, '02.txt')\n",
        "text_02 = read_text_file(text_path_02)\n",
        "\n",
        "text_path_03 = os.path.join(texts_path, '03.txt')\n",
        "text_03 = read_text_file(text_path_03)\n",
        "\n",
        "text_path_04 = os.path.join(texts_path, '04.txt')\n",
        "text_04 = read_text_file(text_path_04)\n",
        "\n",
        "text_path_05 = os.path.join(texts_path, '05.txt')\n",
        "text_05 = read_text_file(text_path_05)"
      ],
      "metadata": {
        "id": "UilQwGRH1Q3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Env"
      ],
      "metadata": {
        "id": "MvKQFU1u0_5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env_path = '/content/drive/MyDrive/credentials/data-analytics-demo/.env'"
      ],
      "metadata": {
        "id": "7kCLrM3G1EDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "load_dotenv(env_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw6Tsu9B1GxJ",
        "outputId": "a13c0000-e6e2-4337-f15a-3d135a10f858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_PALM_API_KEY = os.environ['GOOGLE_PALM_API_KEY']\n",
        "HUGGINGFACE_API_KEY = os.environ['HUGGINGFACE_API_KEY']\n",
        "OPEN_AI_API_KEY = os.environ['OPEN_AI_API_KEY']\n",
        "\n",
        "# GOOGLE_PALM_API_KEY, HUGGINGFACE_API_KEY, OPEN_AI_API_KEY"
      ],
      "metadata": {
        "id": "5UQeEMjW1H0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "enhDeSzG1zSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class MCQModel(BaseModel):\n",
        "  question: str = Field(description=\"This is the question text\")\n",
        "  options: list[str] = Field(description=\"This is a list of multiple choices or options avalible\")\n",
        "  correct_option: str = Field(description=\"This is the correct choice or option\")\n",
        "  difficulty_level: str = Field(description=\"This is the difficulty level of the question from one of the three modes: easy, medium, and hard\")"
      ],
      "metadata": {
        "id": "YrgDBQoi10RG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MCQListModel(BaseModel):\n",
        "  mcq_list: list[MCQModel] = Field(description=\"A list of multiple choice questions\")"
      ],
      "metadata": {
        "id": "aJudkLVv4DoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import PydanticOutputParser\n",
        "\n",
        "pydantic_parser = PydanticOutputParser(pydantic_object=MCQListModel)\n",
        "\n",
        "format_instructions = pydantic_parser.get_format_instructions()\n",
        "\n",
        "print(format_instructions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgOsKVWI13I-",
        "outputId": "47c4231c-fce2-422a-a1d0-43089a149fab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"properties\": {\"mcq_list\": {\"title\": \"Mcq List\", \"description\": \"A list of multiple choice questions\", \"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/MCQModel\"}}}, \"required\": [\"mcq_list\"], \"definitions\": {\"MCQModel\": {\"title\": \"MCQModel\", \"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"description\": \"This is the question text\", \"type\": \"string\"}, \"options\": {\"title\": \"Options\", \"description\": \"This is a list of multiple choices or options avalible\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}, \"correct_option\": {\"title\": \"Correct Option\", \"description\": \"This is the correct choice or option\", \"type\": \"string\"}, \"difficulty_level\": {\"title\": \"Difficulty Level\", \"description\": \"This is the difficulty level of the question from one of the three modes: easy, medium, and hard\", \"type\": \"string\"}}, \"required\": [\"question\", \"options\", \"correct_option\", \"difficulty_level\"]}}}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "langchain_llm = ChatOpenAI(openai_api_key=OPEN_AI_API_KEY, model_name=\"gpt-3.5-turbo-0613\", verbose=False,)"
      ],
      "metadata": {
        "id": "X1V31rQV1_kL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = (\n",
        "    \"Following are blocks of text picked at random from a document:\"\n",
        "    \"\\n{texts}\"\n",
        "    \"\\nGenerate {n} non-repeating multiple choice questions along with their respective correct options from this text.\"\n",
        "    \"\\nBy default the difficulty level is set to {difficulty_level}, if it is mix then randomly select difficulty\"\n",
        "    \"\\nAlso, return the difficulty level of the question from one of the three modes: easy, medium, and hard.\"\n",
        "    \"\\nDo not use any outside information.\"\n",
        "    \"\\n{format_instructions}\"\n",
        ")"
      ],
      "metadata": {
        "id": "8W1XZIeU2Dv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = ChatPromptTemplate.from_template(prompt)\n",
        "\n",
        "prompt_template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cne6dkur2FAj",
        "outputId": "ce28a76f-90dd-4e39-d948-d4bafb4b7e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['difficulty_level', 'format_instructions', 'n', 'texts'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['difficulty_level', 'format_instructions', 'n', 'texts'], template='Following are blocks of text picked at random from a document:\\n{texts}\\nGenerate {n} non-repeating multiple choice questions along with their respective correct options from this text.\\nBy default the difficulty level is set to {difficulty_level}, if it is mix then randomly select difficulty\\nAlso, return the difficulty level of the question from one of the three modes: easy, medium, and hard.\\nDo not use any outside information.\\n{format_instructions}'))])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain = LLMChain(llm=langchain_llm, prompt=prompt_template, output_key=\"result\")"
      ],
      "metadata": {
        "id": "P8STiiBE2HWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_docs(text, chunk_size=500, chunk_overlap=0):\n",
        "  \"\"\"\n",
        "  note:\n",
        "    * When chunk_overlap=0, it will try not cut sentences, which is good for out case\n",
        "  \"\"\"\n",
        "  text_splitter = CharacterTextSplitter(\n",
        "      separator=\"\\n\",\n",
        "      chunk_size=chunk_size,\n",
        "      chunk_overlap=chunk_overlap,\n",
        "      length_function=len,\n",
        "      is_separator_regex=False,\n",
        "  )\n",
        "\n",
        "  docs = text_splitter.create_documents([text])\n",
        "\n",
        "  return docs"
      ],
      "metadata": {
        "id": "TWNgfVom2QxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.callbacks import get_openai_callback as get_langchain_openai_callback\n",
        "\n",
        "import random\n",
        "\n",
        "def get_exam(text, n=3, difficulty_level=\"mix\"):\n",
        "  \"\"\"\n",
        "  validation: total_docs <= n\n",
        "  \"\"\"\n",
        "\n",
        "  docs = get_docs(text)\n",
        "\n",
        "  if n > len(docs):\n",
        "    raise ValueError(f\"Too many questions specified, must be less then {len(docs)+1}\")\n",
        "\n",
        "  rand_docs = random.sample(docs, n)\n",
        "\n",
        "  texts = \"\".join([f\"Text Block {i+1}:\\n{doc.page_content}\\n\" for i, doc in enumerate(rand_docs)])\n",
        "\n",
        "  with get_langchain_openai_callback() as cb_langchain:\n",
        "    response = llm_chain.invoke({\"texts\": texts, \"n\": n, \"difficulty_level\": difficulty_level, \"format_instructions\": format_instructions})\n",
        "\n",
        "  return {\"mcqs_parsed\": MCQListModel.parse_raw(response['result']).mcq_list, 'cb_langchain': cb_langchain}\n",
        "\n",
        "# get_exam(text_01)"
      ],
      "metadata": {
        "id": "L6F9-YwF5jdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing"
      ],
      "metadata": {
        "id": "LI9LhfUU507E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_exam(exam):\n",
        "\n",
        "  for i in exam['mcqs_parsed']:\n",
        "\n",
        "    print(f\"question: {i.question}\\n\")\n",
        "\n",
        "    for index, j in enumerate(i.options):\n",
        "      print(f\"{index+1}. {j}\")\n",
        "\n",
        "    print(f\"\\ncorrect: {i.correct_option}\\n\")\n",
        "\n",
        "    print(f\"difficulty: {i.difficulty_level}\\n\\n\")\n",
        "\n",
        "  print(exam['cb_langchain'])"
      ],
      "metadata": {
        "id": "vR4UOyPh9Tqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exam_01 = get_exam(text_01, n=10)"
      ],
      "metadata": {
        "id": "o7fer6WsCBKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exam_01 = get_exam(text_01, n=5, difficulty_level='hard')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yglnLo5u50Vb",
        "outputId": "21f3683c-863f-4ef6-c49e-ece5f7ed8c5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 509, which is longer than the specified 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_exam(exam_01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oo-hLcQx7sn7",
        "outputId": "cc55f6b8-9e3a-4fa0-fd61-b6a73f68fff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question: What did Seraphina take with her on her journey?\n",
            "\n",
            "1. A weathered satchel\n",
            "2. A compass\n",
            "3. The shimmering artifact\n",
            "4. All of the above\n",
            "\n",
            "correct: All of the above\n",
            "\n",
            "difficulty: hard\n",
            "\n",
            "\n",
            "question: Where did Seraphina live?\n",
            "\n",
            "1. Eldridge Haven\n",
            "2. A small coastal village\n",
            "3. A close-knit community\n",
            "4. All of the above\n",
            "\n",
            "correct: All of the above\n",
            "\n",
            "difficulty: hard\n",
            "\n",
            "\n",
            "question: What did Seraphina become after her journey?\n",
            "\n",
            "1. A curious villager\n",
            "2. A guardian of realms\n",
            "3. A young woman\n",
            "4. None of the above\n",
            "\n",
            "correct: A guardian of realms\n",
            "\n",
            "difficulty: hard\n",
            "\n",
            "\n",
            "question: What did Seraphina discover in the archipelago?\n",
            "\n",
            "1. Lost civilizations\n",
            "2. Forgotten magic\n",
            "3. A realm suspended between reality and dreams\n",
            "4. All of the above\n",
            "\n",
            "correct: All of the above\n",
            "\n",
            "difficulty: hard\n",
            "\n",
            "\n",
            "question: What triggered Seraphina's journey?\n",
            "\n",
            "1. A stroll along the shore\n",
            "2. The beating of her heart\n",
            "3. The desire for adventure\n",
            "4. All of the above\n",
            "\n",
            "correct: All of the above\n",
            "\n",
            "difficulty: hard\n",
            "\n",
            "\n",
            "Tokens Used: 1313\n",
            "\tPrompt Tokens: 940\n",
            "\tCompletion Tokens: 373\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.002156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exam_02 = get_exam(text_02, n=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1IfHfV8-Mro",
        "outputId": "7dc35e45-56d9-498e-ceaa-462c62be6b23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 520, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 609, which is longer than the specified 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_exam(exam_02)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnmZ1dIK_4NJ",
        "outputId": "969a39a4-1d42-402d-a1f9-371943e1794e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question: What fields were revolutionized by SynthEra?\n",
            "\n",
            "1. a) Engineering, finance, and technology\n",
            "2. b) Medicine, education, and entertainment\n",
            "3. c) Science, art, and politics\n",
            "4. d) Communication, transportation, and agriculture\n",
            "\n",
            "correct: b) Medicine, education, and entertainment\n",
            "\n",
            "difficulty: medium\n",
            "\n",
            "\n",
            "question: What could users do with SynthEra?\n",
            "\n",
            "1. a) Teleport to different locations\n",
            "2. b) Control their dreams\n",
            "3. c) Manipulate the virtual environment around them\n",
            "4. d) Predict the future\n",
            "\n",
            "correct: c) Manipulate the virtual environment around them\n",
            "\n",
            "difficulty: easy\n",
            "\n",
            "\n",
            "question: What were the ethical considerations associated with SynthEra?\n",
            "\n",
            "1. a) Environmental impact, economic inequality, and resource depletion\n",
            "2. b) Privacy, security, and potential misuse of access to the human mind\n",
            "3. c) Education reform, cultural preservation, and social justice\n",
            "4. d) Political instability, technological unemployment, and global governance\n",
            "\n",
            "correct: b) Privacy, security, and potential misuse of access to the human mind\n",
            "\n",
            "difficulty: hard\n",
            "\n",
            "\n",
            "question: How did SynthEra establish a connection between the human brain and digital information?\n",
            "\n",
            "1. a) By directly altering the structure of the human brain\n",
            "2. b) By connecting the user's thoughts to the internet\n",
            "3. c) By using a neuro-interface headset and advanced neurostimulation algorithms\n",
            "4. d) By creating a digital replica of the user's brain\n",
            "\n",
            "correct: c) By using a neuro-interface headset and advanced neurostimulation algorithms\n",
            "\n",
            "difficulty: medium\n",
            "\n",
            "\n",
            "question: Where did SynthEra originate from?\n",
            "\n",
            "1. a) Quantum Dynamics Innovations\n",
            "2. b) SynthEra Laboratories\n",
            "3. c) The Future Technology Institute\n",
            "4. d) The Department of Neurology\n",
            "\n",
            "correct: a) Quantum Dynamics Innovations\n",
            "\n",
            "difficulty: easy\n",
            "\n",
            "\n",
            "Tokens Used: 1373\n",
            "\tPrompt Tokens: 860\n",
            "\tCompletion Tokens: 513\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.002316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exam_03 = get_exam(text_03, n=5)"
      ],
      "metadata": {
        "id": "FVUrKbiY_uik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_exam(exam_03)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIRQ_H5O_5Rq",
        "outputId": "7fd29f77-0b85-494c-c3fd-55892caeaa12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question: What is the Collatz conjecture?\n",
            "\n",
            "1. A problem in abstract mathematics\n",
            "2. A puzzle in number theory\n",
            "3. A theorem proven by Lothar Collatz\n",
            "4. A cycle of numbers: 4, 2, 1\n",
            "\n",
            "correct: A problem in abstract mathematics\n",
            "\n",
            "difficulty: medium\n",
            "\n",
            "\n",
            "question: What makes the Collatz conjecture challenging?\n",
            "\n",
            "1. Its simplicity\n",
            "2. Its complexity\n",
            "3. The involvement of German mathematicians\n",
            "4. The predictable patterns in the sequence\n",
            "\n",
            "correct: Its complexity\n",
            "\n",
            "difficulty: easy\n",
            "\n",
            "\n",
            "question: What behavior does the Collatz sequence exhibit?\n",
            "\n",
            "1. Erratic and unpredictable\n",
            "2. Convergent and predictable\n",
            "3. Cyclic and repetitive\n",
            "4. Chaotic and random\n",
            "\n",
            "correct: Erratic and unpredictable\n",
            "\n",
            "difficulty: medium\n",
            "\n",
            "\n",
            "question: Why do mathematicians find the Collatz conjecture intriguing?\n",
            "\n",
            "1. Its inaccessibility to amateurs\n",
            "2. Its predictable patterns\n",
            "3. Its simplicity and depth\n",
            "4. Its reliance on prime numbers\n",
            "\n",
            "correct: Its simplicity and depth\n",
            "\n",
            "difficulty: easy\n",
            "\n",
            "\n",
            "question: What are the rules of the Collatz conjecture?\n",
            "\n",
            "1. Divide by 2 if even, triple and add 1 if odd\n",
            "2. Divide by 3 if even, add 1 if odd\n",
            "3. Multiply by 2 if even, subtract 1 if odd\n",
            "4. Multiply by 3 if even, subtract 1 if odd\n",
            "\n",
            "correct: Divide by 2 if even, triple and add 1 if odd\n",
            "\n",
            "difficulty: hard\n",
            "\n",
            "\n",
            "Tokens Used: 1308\n",
            "\tPrompt Tokens: 872\n",
            "\tCompletion Tokens: 436\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.00218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exam_04 = get_exam(text_04, n=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSen-fHg_u9K",
        "outputId": "3a1d7bd6-8b9d-4e53-f1d1-39a320904e44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 567, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 531, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 577, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 516, which is longer than the specified 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_exam(exam_04)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21Uzx3-p_6kC",
        "outputId": "ae0991e9-335d-4d4e-edab-97b7a63ece48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question: What is the potency of poetry?\n",
            "\n",
            "1. Its articulated lexicon\n",
            "2. Verbal modulations\n",
            "3. The intervals of pregnant reticence\n",
            "4. All of the above\n",
            "\n",
            "correct: All of the above\n",
            "\n",
            "difficulty: medium\n",
            "\n",
            "\n",
            "question: What does poetry transcend?\n",
            "\n",
            "1. Linguistic demarcations\n",
            "2. Temporal epochs\n",
            "3. Both A and B\n",
            "4. None of the above\n",
            "\n",
            "correct: Both A and B\n",
            "\n",
            "difficulty: medium\n",
            "\n",
            "\n",
            "question: What does the art of compaction in poetry entail?\n",
            "\n",
            "1. Distilling intricate emotions\n",
            "2. Endowing the abstract with palpability\n",
            "3. Unveiling profound verities\n",
            "4. All of the above\n",
            "\n",
            "correct: All of the above\n",
            "\n",
            "difficulty: medium\n",
            "\n",
            "\n",
            "question: What does each poetic modality offer?\n",
            "\n",
            "1. A distinctive perspective\n",
            "2. A unique rhythm\n",
            "3. A specific theme\n",
            "4. None of the above\n",
            "\n",
            "correct: A distinctive perspective\n",
            "\n",
            "difficulty: medium\n",
            "\n",
            "\n",
            "question: What does the choreography of syllabic configurations and rhythmic resonances do?\n",
            "\n",
            "1. Imbues poets with expressive profundity\n",
            "2. Metamorphoses prosaic verbiage\n",
            "3. Creates an intricate mosaic\n",
            "4. All of the above\n",
            "\n",
            "correct: All of the above\n",
            "\n",
            "difficulty: medium\n",
            "\n",
            "\n",
            "Tokens Used: 1374\n",
            "\tPrompt Tokens: 988\n",
            "\tCompletion Tokens: 386\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.002254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exam_05 = get_exam(text_05, n=5)"
      ],
      "metadata": {
        "id": "FNBbpIx3_vQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_exam(exam_05)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8w_fLRB2_7wS",
        "outputId": "0f5f3218-4aa0-48a5-eba3-b187e50c7107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question: What is the name of the large-scale language model developed by OpenAI?\n",
            "\n",
            "1. GPT-2\n",
            "2. GPT-3\n",
            "3. BERT\n",
            "4. ELMO\n",
            "\n",
            "correct: GPT-3\n",
            "\n",
            "difficulty: easy\n",
            "\n",
            "\n",
            "question: Which architecture revolutionized natural language processing by introducing the self-attention mechanism?\n",
            "\n",
            "1. RNN\n",
            "2. LSTM\n",
            "3. GRU\n",
            "4. Transformer\n",
            "\n",
            "correct: Transformer\n",
            "\n",
            "difficulty: medium\n",
            "\n",
            "\n",
            "question: What is the main concern associated with the evolution of Large Language Models?\n",
            "\n",
            "1. Bias\n",
            "2. Performance\n",
            "3. Accuracy\n",
            "4. Interpretability\n",
            "\n",
            "correct: Bias\n",
            "\n",
            "difficulty: easy\n",
            "\n",
            "\n",
            "question: In which year was the transformer model introduced?\n",
            "\n",
            "1. 2015\n",
            "2. 2016\n",
            "3. 2017\n",
            "4. 2018\n",
            "\n",
            "correct: 2017\n",
            "\n",
            "difficulty: medium\n",
            "\n",
            "\n",
            "question: Which approach in natural language processing outperformed rule-based systems in the late 20th century?\n",
            "\n",
            "1. Statistical\n",
            "2. Rule-based\n",
            "3. Symbolic\n",
            "4. Semantic\n",
            "\n",
            "correct: Statistical\n",
            "\n",
            "difficulty: easy\n",
            "\n",
            "\n",
            "Tokens Used: 1117\n",
            "\tPrompt Tokens: 808\n",
            "\tCompletion Tokens: 309\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.0018300000000000002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AIZO_U_H_9Uo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}