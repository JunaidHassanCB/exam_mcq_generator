{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction"
      ],
      "metadata": {
        "id": "Krv9LtD10hV0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Title: Exam MCQ Generator"
      ],
      "metadata": {
        "id": "NdYnWlds0jwO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Installs"
      ],
      "metadata": {
        "id": "5hZMS8Bt0y_7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsGNHKnc0RxY",
        "outputId": "ebd4270c-cf26-4586-cf9d-ea1a9ff94b25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.0/163.0 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.3/803.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.5/215.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.7/224.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q python-dotenv\n",
        "\n",
        "!pip install -q langchain_experimental\n",
        "!pip install -q langchain\n",
        "\n",
        "!pip install -q openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pydantic"
      ],
      "metadata": {
        "id": "1Yx1gXrn01rT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the rapidocr-onnxruntime package we can extract images as text as well"
      ],
      "metadata": {
        "id": "OPpqncrM9CGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf rapidocr-onnxruntime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYW88amo5cRZ",
        "outputId": "2eef7673-55db-418e-ec15-5a435dbb76b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (3.17.4)\n",
            "Collecting rapidocr-onnxruntime\n",
            "  Downloading rapidocr_onnxruntime-1.3.9-py3-none-any.whl (14.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyclipper>=1.2.0 (from rapidocr-onnxruntime)\n",
            "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.7.0 (from rapidocr-onnxruntime)\n",
            "  Downloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=4.5.1.48 in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (1.23.5)\n",
            "Requirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (1.16.0)\n",
            "Requirement already satisfied: Shapely>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (2.0.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (6.0.1)\n",
            "Requirement already satisfied: Pillow<=10.0.1 in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (9.4.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.7.0->rapidocr-onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (23.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (1.12)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.7.0->rapidocr-onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.7.0->rapidocr-onnxruntime) (1.3.0)\n",
            "Installing collected packages: pyclipper, humanfriendly, coloredlogs, onnxruntime, rapidocr-onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.16.3 pyclipper-1.3.0.post5 rapidocr-onnxruntime-1.3.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "um-apBad03iv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "Fa6Q5e8V02S-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Source"
      ],
      "metadata": {
        "id": "pE6jPUrZ0652"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnv-pYxs06eg",
        "outputId": "8ba89d58-5865-4c24-dfd0-de90b388aa8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_text_file(path):\n",
        "  with open(path, 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "  return text"
      ],
      "metadata": {
        "id": "jGhEuJEr1huL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts_path = '/content/drive/MyDrive/datasets/exam_mcq_generator/texts'\n",
        "\n",
        "text_path_01 = os.path.join(texts_path, '01.txt')\n",
        "text_path_02 = os.path.join(texts_path, '02.txt')\n",
        "text_path_03 = os.path.join(texts_path, '03.txt')\n",
        "text_path_04 = os.path.join(texts_path, '04.txt')\n",
        "text_path_05 = os.path.join(texts_path, '05.txt')"
      ],
      "metadata": {
        "id": "UilQwGRH1Q3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdfs_path = '/content/drive/MyDrive/datasets/exam_mcq_generator/pdfs'\n",
        "\n",
        "pdf_path_the_time_machine = os.path.join(pdfs_path, 'The-Time-Machine.pdf')\n",
        "pdf_path_pdf_test_01 = os.path.join(pdfs_path, 'pdf_test_01.pdf')"
      ],
      "metadata": {
        "id": "A75VZbeP4gmi"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Env"
      ],
      "metadata": {
        "id": "MvKQFU1u0_5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env_path = '/content/drive/MyDrive/credentials/data-analytics-demo/.env'"
      ],
      "metadata": {
        "id": "7kCLrM3G1EDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "load_dotenv(env_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw6Tsu9B1GxJ",
        "outputId": "ac71fa71-40d4-4eb3-835e-dc3165655dd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_PALM_API_KEY = os.environ['GOOGLE_PALM_API_KEY']\n",
        "HUGGINGFACE_API_KEY = os.environ['HUGGINGFACE_API_KEY']\n",
        "OPEN_AI_API_KEY = os.environ['OPEN_AI_API_KEY']\n",
        "\n",
        "# GOOGLE_PALM_API_KEY, HUGGINGFACE_API_KEY, OPEN_AI_API_KEY"
      ],
      "metadata": {
        "id": "5UQeEMjW1H0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "enhDeSzG1zSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class MCQModel(BaseModel):\n",
        "  question: str = Field(description=\"This is the question text\")\n",
        "  options: list[str] = Field(description=\"This is a list of multiple choices or options avalible\")\n",
        "  correct_option: str = Field(description=\"This is the correct choice or option\")\n",
        "  difficulty_level: str = Field(description=\"This is the difficulty level of the question from one of the three modes: easy, medium, and hard\")"
      ],
      "metadata": {
        "id": "YrgDBQoi10RG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MCQListModel(BaseModel):\n",
        "  mcq_list: list[MCQModel] = Field(description=\"A list of multiple choice questions\")"
      ],
      "metadata": {
        "id": "aJudkLVv4DoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import PydanticOutputParser\n",
        "\n",
        "pydantic_parser = PydanticOutputParser(pydantic_object=MCQListModel)\n",
        "\n",
        "format_instructions = pydantic_parser.get_format_instructions()\n",
        "\n",
        "print(format_instructions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgOsKVWI13I-",
        "outputId": "348547d9-c37d-42e1-9912-a6980b4b3ff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"properties\": {\"mcq_list\": {\"title\": \"Mcq List\", \"description\": \"A list of multiple choice questions\", \"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/MCQModel\"}}}, \"required\": [\"mcq_list\"], \"definitions\": {\"MCQModel\": {\"title\": \"MCQModel\", \"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"description\": \"This is the question text\", \"type\": \"string\"}, \"options\": {\"title\": \"Options\", \"description\": \"This is a list of multiple choices or options avalible\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}, \"correct_option\": {\"title\": \"Correct Option\", \"description\": \"This is the correct choice or option\", \"type\": \"string\"}, \"difficulty_level\": {\"title\": \"Difficulty Level\", \"description\": \"This is the difficulty level of the question from one of the three modes: easy, medium, and hard\", \"type\": \"string\"}}, \"required\": [\"question\", \"options\", \"correct_option\", \"difficulty_level\"]}}}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "langchain_llm = ChatOpenAI(openai_api_key=OPEN_AI_API_KEY, model_name=\"gpt-3.5-turbo-0613\", verbose=False,)"
      ],
      "metadata": {
        "id": "X1V31rQV1_kL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c71dc31e-06f8-4c39-cb84-397f93cf5b8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:115: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.ChatOpenAI instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = (\n",
        "    \"Following are blocks of text picked at random from a document:\"\n",
        "    \"\\n{texts}\"\n",
        "    \"\\nGenerate {n} non-repeating multiple choice questions along with their respective correct options from this text.\"\n",
        "    \"\\nBy default the difficulty level is set to {difficulty_level}, if it is mix then randomly select difficulty\"\n",
        "    \"\\nAlso, return the difficulty level of the question from one of the three modes: easy, medium, and hard.\"\n",
        "    \"\\nDo not use any outside information.\"\n",
        "    \"\\n{format_instructions}\"\n",
        ")"
      ],
      "metadata": {
        "id": "8W1XZIeU2Dv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = ChatPromptTemplate.from_template(prompt)\n",
        "\n",
        "prompt_template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cne6dkur2FAj",
        "outputId": "266e858a-d3d4-467f-8780-7ef3872d99de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['difficulty_level', 'format_instructions', 'n', 'texts'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['difficulty_level', 'format_instructions', 'n', 'texts'], template='Following are blocks of text picked at random from a document:\\n{texts}\\nGenerate {n} non-repeating multiple choice questions along with their respective correct options from this text.\\nBy default the difficulty level is set to {difficulty_level}, if it is mix then randomly select difficulty\\nAlso, return the difficulty level of the question from one of the three modes: easy, medium, and hard.\\nDo not use any outside information.\\n{format_instructions}'))])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain = LLMChain(llm=langchain_llm, prompt=prompt_template, output_key=\"result\")"
      ],
      "metadata": {
        "id": "P8STiiBE2HWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_docs_text(path, chunk_size=500, chunk_overlap=0):\n",
        "  \"\"\"\n",
        "  note:\n",
        "    * When chunk_overlap=0, it will try not cut sentences, which is good for out case\n",
        "  \"\"\"\n",
        "\n",
        "  text = read_text_file(path)\n",
        "\n",
        "  text_splitter = CharacterTextSplitter(\n",
        "      separator=\"\\n\",\n",
        "      chunk_size=chunk_size,\n",
        "      chunk_overlap=chunk_overlap,\n",
        "      length_function=len,\n",
        "      is_separator_regex=False,\n",
        "  )\n",
        "\n",
        "  docs = text_splitter.create_documents([text])\n",
        "\n",
        "  return docs"
      ],
      "metadata": {
        "id": "TWNgfVom2QxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "def get_docs_pdf(path, chunk_size=500, chunk_overlap=0):\n",
        "  \"\"\"\n",
        "  note:\n",
        "    * When chunk_overlap=0, it will try not cut sentences, which is good for out case\n",
        "  \"\"\"\n",
        "\n",
        "  loader = PyPDFLoader(path, extract_images=True)\n",
        "\n",
        "  text_splitter = CharacterTextSplitter(\n",
        "      separator=\"\\n\",\n",
        "      chunk_size=chunk_size,\n",
        "      chunk_overlap=chunk_overlap,\n",
        "      length_function=len,\n",
        "      is_separator_regex=False,\n",
        "  )\n",
        "\n",
        "  # by default it was doing page split\n",
        "  docs = loader.load_and_split(text_splitter=text_splitter)\n",
        "\n",
        "  return docs"
      ],
      "metadata": {
        "id": "jo39XnnX7ZkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.callbacks import get_openai_callback as get_langchain_openai_callback\n",
        "\n",
        "import random\n",
        "\n",
        "class InvalidFileExtensionError(Exception):\n",
        "    pass\n",
        "\n",
        "def get_exam(file_path, n=3, difficulty_level=\"mix\"):\n",
        "  \"\"\"\n",
        "  validation: total_docs <= n\n",
        "  \"\"\"\n",
        "\n",
        "  if not os.path.exists(file_path):\n",
        "    raise FileNotFoundError(f\"File not found: {file_path}\")\n",
        "\n",
        "  _, file_extension = os.path.splitext(file_path)\n",
        "\n",
        "  if file_extension == '.txt':\n",
        "    docs = get_docs_text(file_path)\n",
        "  elif file_extension == '.pdf':\n",
        "    docs = get_docs_pdf(file_path)\n",
        "  else:\n",
        "    raise InvalidFileExtensionError(f\"Invalid file extension: {file_extension}\")\n",
        "\n",
        "  if n > len(docs):\n",
        "    raise ValueError(f\"Too many questions specified, must be less then {len(docs)+1}\")\n",
        "\n",
        "  rand_docs = random.sample(docs, n)\n",
        "\n",
        "  texts = \"\".join([f\"Text Block {i+1}:\\n{doc.page_content}\\n\" for i, doc in enumerate(rand_docs)])\n",
        "\n",
        "  with get_langchain_openai_callback() as cb_langchain:\n",
        "    response = llm_chain.invoke({\"texts\": texts, \"n\": n, \"difficulty_level\": difficulty_level, \"format_instructions\": format_instructions})\n",
        "\n",
        "  return {\"mcqs_parsed\": MCQListModel.parse_raw(response['result']).mcq_list, 'cb_langchain': cb_langchain}\n",
        "\n",
        "# get_exam(text_01)"
      ],
      "metadata": {
        "id": "L6F9-YwF5jdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing Text"
      ],
      "metadata": {
        "id": "LI9LhfUU507E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_exam(exam):\n",
        "\n",
        "  for i in exam['mcqs_parsed']:\n",
        "\n",
        "    print(f\"question: {i.question}\\n\")\n",
        "\n",
        "    for index, j in enumerate(i.options):\n",
        "      print(f\"{index+1}. {j}\")\n",
        "\n",
        "    print(f\"\\ncorrect: {i.correct_option}\\n\")\n",
        "\n",
        "    print(f\"difficulty: {i.difficulty_level}\\n\\n\")\n",
        "\n",
        "  print(exam['cb_langchain'])"
      ],
      "metadata": {
        "id": "vR4UOyPh9Tqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exam_01 = get_exam(text_01, n=10)"
      ],
      "metadata": {
        "id": "o7fer6WsCBKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exam_01 = get_exam(text_path_01, n=5, difficulty_level='hard')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yglnLo5u50Vb",
        "outputId": "f53b6b9c-68f6-4f84-a1f3-5e4fadea5701"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 509, which is longer than the specified 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_exam(exam_01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oo-hLcQx7sn7",
        "outputId": "7cf033ae-dc45-485d-cd53-8ea48be7f68c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question: What did Seraphina discover about the archipelago?\n",
            "\n",
            "1. It was home to mythical creatures\n",
            "2. It held the key to a realm between reality and dreams\n",
            "3. It was a lost civilization with forgotten magic\n",
            "4. It had boundaries of time and space intertwined\n",
            "\n",
            "correct: It held the key to a realm between reality and dreams\n",
            "\n",
            "difficulty: hard\n",
            "\n",
            "\n",
            "question: What did Eldridge Haven stand as a testament to?\n",
            "\n",
            "1. The enduring power of curiosity\n",
            "2. The enduring power of courage\n",
            "3. The enduring power of uncharted territories\n",
            "4. The enduring power of curiosity, courage, and uncharted territories\n",
            "\n",
            "correct: The enduring power of curiosity, courage, and uncharted territories\n",
            "\n",
            "difficulty: medium\n",
            "\n",
            "\n",
            "question: What did Seraphina take with her on her journey?\n",
            "\n",
            "1. A weathered satchel, a compass, and the shimmering artifact\n",
            "2. A compass and the ancient map\n",
            "3. A weathered satchel and the shimmering artifact\n",
            "4. A compass, the ancient map, and the shimmering artifact\n",
            "\n",
            "correct: A weathered satchel, a compass, and the shimmering artifact\n",
            "\n",
            "difficulty: easy\n",
            "\n",
            "\n",
            "question: What happened during Seraphina's solitary stroll along the shore?\n",
            "\n",
            "1. She encountered mythical creatures\n",
            "2. She discovered the fabric of her familiar existence\n",
            "3. She felt the beating of her heart\n",
            "4. She unravelled the mysteries hidden within the ancient map\n",
            "\n",
            "correct: She unravelled the mysteries hidden within the ancient map\n",
            "\n",
            "difficulty: medium\n",
            "\n",
            "\n",
            "question: What stirred within Seraphina's soul in the village of Eldridge Haven?\n",
            "\n",
            "1. The rhythmic ebb and flow of tide\n",
            "2. The sweet fragrance of blooming flowers\n",
            "3. The undercurrent of restlessness\n",
            "4. The gentle whispers of the wind through ancient willows\n",
            "\n",
            "correct: The undercurrent of restlessness\n",
            "\n",
            "difficulty: hard\n",
            "\n",
            "\n",
            "Tokens Used: 1422\n",
            "\tPrompt Tokens: 911\n",
            "\tCompletion Tokens: 511\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.0023885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exam_02 = get_exam(text_path_02, n=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1IfHfV8-Mro",
        "outputId": "bcda9a1a-c949-40f6-bf4a-de962f158eac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 520, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 609, which is longer than the specified 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_exam(exam_02)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnmZ1dIK_4NJ",
        "outputId": "934893fd-397e-4f4a-919f-304606f5d342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question: What emerged as SynthEra became more ubiquitous?\n",
            "\n",
            "1. A) A vibrant subculture\n",
            "2. B) A new era of human expression\n",
            "3. C) The intersection of technology and creativity\n",
            "4. D) The boundaries between the tangible and the virtual\n",
            "\n",
            "correct: A) A vibrant subculture\n",
            "\n",
            "difficulty: easy\n",
            "\n",
            "\n",
            "question: What were some of the ethical considerations with SynthEra?\n",
            "\n",
            "1. A) Privacy and security\n",
            "2. B) Potential misuse of intimate access to the human mind\n",
            "3. C) Innovation and responsibility\n",
            "4. D) All of the above\n",
            "\n",
            "correct: D) All of the above\n",
            "\n",
            "difficulty: medium\n",
            "\n",
            "\n",
            "question: What were some of the possibilities unlocked by SynthEra?\n",
            "\n",
            "1. A) Interacting with augmented reality overlays\n",
            "2. B) Accessing vast databases and analyzing complex data sets\n",
            "3. C) Communicating with others in a purely mental dialogue\n",
            "4. D) All of the above\n",
            "\n",
            "correct: D) All of the above\n",
            "\n",
            "difficulty: medium\n",
            "\n",
            "\n",
            "question: Where did SynthEra originate from?\n",
            "\n",
            "1. A) Quantum Dynamics Innovations\n",
            "2. B) Laboratories of Quantum Dynamics Innovations\n",
            "3. C) Quantum Dynamics Innovations' revolutionary technological marvel\n",
            "4. D) None of the above\n",
            "\n",
            "correct: B) Laboratories of Quantum Dynamics Innovations\n",
            "\n",
            "difficulty: easy\n",
            "\n",
            "\n",
            "question: In which sectors did SynthEra have a significant impact?\n",
            "\n",
            "1. A) Medicine, education, and entertainment\n",
            "2. B) Healthcare, education, and technology\n",
            "3. C) Medicine, education, and technology\n",
            "4. D) Healthcare, education, and entertainment\n",
            "\n",
            "correct: A) Medicine, education, and entertainment\n",
            "\n",
            "difficulty: hard\n",
            "\n",
            "\n",
            "Tokens Used: 1326\n",
            "\tPrompt Tokens: 854\n",
            "\tCompletion Tokens: 472\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.002225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exam_03 = get_exam(text_path_03, n=5)"
      ],
      "metadata": {
        "id": "FVUrKbiY_uik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_exam(exam_03)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIRQ_H5O_5Rq",
        "outputId": "32c2f6e5-60c1-43fa-ac7e-dfa0b77ddf5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question: What is the Collatz conjecture?\n",
            "\n",
            "1. A mathematical puzzle that has been solved\n",
            "2. A philosophical question about the nature of truth\n",
            "3. A conundrum in abstract mathematics\n",
            "4. A cycle of numbers that repeats endlessly\n",
            "\n",
            "correct: A conundrum in abstract mathematics\n",
            "\n",
            "difficulty: medium\n",
            "\n",
            "\n",
            "question: What is the core rule of the Collatz conjecture?\n",
            "\n",
            "1. Divide any positive integer by 2\n",
            "2. Triple any positive integer and add 1\n",
            "3. Take the square root of any positive integer\n",
            "4. Add 1 to any positive integer\n",
            "\n",
            "correct: Divide any positive integer by 2\n",
            "\n",
            "difficulty: easy\n",
            "\n",
            "\n",
            "question: What is the significance of the Collatz conjecture?\n",
            "\n",
            "1. It provides a solution to a mathematical puzzle\n",
            "2. It deepens our understanding of the beauty of numbers\n",
            "3. It challenges the core of mathematical understanding\n",
            "4. It reveals the secrets of the infinite realms of possibility\n",
            "\n",
            "correct: It challenges the core of mathematical understanding\n",
            "\n",
            "difficulty: medium\n",
            "\n",
            "\n",
            "question: What happens to the sequence in the Collatz conjecture?\n",
            "\n",
            "1. It eventually reaches a cycle of 4, 2, 1\n",
            "2. It grows infinitely without any pattern\n",
            "3. It converges towards a specific number\n",
            "4. It becomes chaotic and unpredictable\n",
            "\n",
            "correct: It eventually reaches a cycle of 4, 2, 1\n",
            "\n",
            "difficulty: easy\n",
            "\n",
            "\n",
            "question: What did mathematicians discover about the Collatz conjecture?\n",
            "\n",
            "1. It follows a predictable pattern for all numbers\n",
            "2. It becomes more chaotic as the numbers increase\n",
            "3. It can be solved using computational approaches\n",
            "4. It is a simple problem with a straightforward solution\n",
            "\n",
            "correct: It becomes more chaotic as the numbers increase\n",
            "\n",
            "difficulty: medium\n",
            "\n",
            "\n",
            "Tokens Used: 1407\n",
            "\tPrompt Tokens: 923\n",
            "\tCompletion Tokens: 484\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.0023525\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exam_04 = get_exam(text_path_04, n=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSen-fHg_u9K",
        "outputId": "13ccfbc1-b820-4d4e-c74e-91d30dd8050a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 567, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 531, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 577, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 516, which is longer than the specified 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_exam(exam_04)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21Uzx3-p_6kC",
        "outputId": "57e8db63-51d0-4feb-914a-bbdfb1630d77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question: What does poetry do in the human experience?\n",
            "\n",
            "1. Forge connections between hearts and intellects\n",
            "2. Offer refuge for introspection and contemplation\n",
            "3. Distill intricate emotions into a paltry ensemble of words\n",
            "4. Transcend linguistic and temporal boundaries\n",
            "5. Manifest in sundry configurations and idioms\n",
            "\n",
            "correct: D\n",
            "\n",
            "difficulty: easy\n",
            "\n",
            "\n",
            "question: What is the primary function of poetry?\n",
            "\n",
            "1. To evoke, inspire, and transcend\n",
            "2. To serve as an emollient for the psyche\n",
            "3. To distill intricate emotions into a paltry ensemble of words\n",
            "4. To connect cultures and epochs\n",
            "5. To manifest in sundry configurations and idioms\n",
            "\n",
            "correct: A\n",
            "\n",
            "difficulty: easy\n",
            "\n",
            "\n",
            "question: What is the art of compaction in poetry?\n",
            "\n",
            "1. The ability to distill intricate emotions into a paltry ensemble of words\n",
            "2. The transcendence of linguistic demarcations\n",
            "3. The ability to connect cultures and epochs\n",
            "4. The manifestation in sundry configurations and idioms\n",
            "5. The weaving of incantations that transport readers\n",
            "\n",
            "correct: A\n",
            "\n",
            "difficulty: medium\n",
            "\n",
            "\n",
            "question: What does poetry transcend?\n",
            "\n",
            "1. Linguistic demarcations\n",
            "2. Temporal epochs\n",
            "3. Chronological and spatial coordinates\n",
            "4. Aesthetic inclinations\n",
            "5. The constraints of human experience\n",
            "\n",
            "correct: C\n",
            "\n",
            "difficulty: medium\n",
            "\n",
            "\n",
            "question: What is the significance of poetic modality?\n",
            "\n",
            "1. To distill meaning from a cacophonous milieu\n",
            "2. To connect cultures and epochs\n",
            "3. To provoke introspection and contemplation\n",
            "4. To scrutinize the human milieu\n",
            "5. To manifest in sundry configurations and idioms\n",
            "\n",
            "correct: D\n",
            "\n",
            "difficulty: hard\n",
            "\n",
            "\n",
            "Tokens Used: 1481\n",
            "\tPrompt Tokens: 1004\n",
            "\tCompletion Tokens: 477\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.00246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exam_05 = get_exam(text_path_05, n=5)"
      ],
      "metadata": {
        "id": "FNBbpIx3_vQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_exam(exam_05)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8w_fLRB2_7wS",
        "outputId": "fa344e15-56e9-4d34-fbee-8edcc1a477ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question: What is the focus of ongoing research on LLMs?\n",
            "\n",
            "1. Refining statistical approaches\n",
            "2. Addressing ethical concerns\n",
            "3. Exploring novel applications\n",
            "4. All of the above\n",
            "\n",
            "correct: All of the above\n",
            "\n",
            "difficulty: easy\n",
            "\n",
            "\n",
            "question: Which experiment in the mid-20th century marked a pioneering effort in computer-based language translation?\n",
            "\n",
            "1. The Georgetown-IBM experiment\n",
            "2. The statistical language model experiment\n",
            "3. The advent of neural networks\n",
            "4. None of the above\n",
            "\n",
            "correct: The Georgetown-IBM experiment\n",
            "\n",
            "difficulty: easy\n",
            "\n",
            "\n",
            "question: Which approach in the late 20th century led to a paradigm shift in natural language processing?\n",
            "\n",
            "1. Rule-based systems\n",
            "2. Statistical approaches\n",
            "3. Computational linguistics\n",
            "4. Neural networks\n",
            "\n",
            "correct: Statistical approaches\n",
            "\n",
            "difficulty: medium\n",
            "\n",
            "\n",
            "question: What was the key breakthrough in the evolution of LLMs in the 21st century?\n",
            "\n",
            "1. Introduction of recurrent neural networks\n",
            "2. Rise of computational linguistics\n",
            "3. Development of rule-based systems\n",
            "4. None of the above\n",
            "\n",
            "correct: Introduction of recurrent neural networks\n",
            "\n",
            "difficulty: medium\n",
            "\n",
            "\n",
            "question: What advantage did recurrent neural networks (RNNs) and long short-term memory networks (LSTMs) bring to LLMs?\n",
            "\n",
            "1. Improved computational power\n",
            "2. Enhanced linguistic nuance\n",
            "3. Ability to capture contextual dependencies\n",
            "4. None of the above\n",
            "\n",
            "correct: Ability to capture contextual dependencies\n",
            "\n",
            "difficulty: hard\n",
            "\n",
            "\n",
            "Tokens Used: 1268\n",
            "\tPrompt Tokens: 842\n",
            "\tCompletion Tokens: 426\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.002115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing PDF"
      ],
      "metadata": {
        "id": "2XeBf25y9Vha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get_docs_pdf(pdf_path_the_time_machine)"
      ],
      "metadata": {
        "id": "wZX4t_aV-NRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exam_06 = get_exam(pdf_path_the_time_machine, n=5, difficulty_level='hard')"
      ],
      "metadata": {
        "id": "AIZO_U_H_9Uo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22527421-4ca0-4e68-d43e-fc3d04a11666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:124: UserWarning: Unknown PDF Filter!\n",
            "  warnings.warn(\"Unknown PDF Filter!\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_exam(exam_06)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3k9LchyR_bFK",
        "outputId": "500818f6-cda1-4b90-fad5-73f65ad66a85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question: What did the narrator see after entering the tunnel?\n",
            "\n",
            "1. A large open space\n",
            "2. A narrow tunnel\n",
            "3. A vast arched cavern\n",
            "4. Utter darkness\n",
            "\n",
            "correct: A vast arched cavern\n",
            "\n",
            "difficulty: medium\n",
            "\n",
            "\n",
            "question: What was the narrator's interpretation of the things they saw?\n",
            "\n",
            "1. The whole earth had become a garden\n",
            "2. There were signs of agriculture\n",
            "3. The whole earth had become a desert\n",
            "4. The whole earth had become a forest\n",
            "\n",
            "correct: The whole earth had become a garden\n",
            "\n",
            "difficulty: medium\n",
            "\n",
            "\n",
            "question: What did the narrator do to escape from the Morlocks?\n",
            "\n",
            "1. Lit another match and retreated to the tunnel\n",
            "2. Ran towards the open space\n",
            "3. Fought against the Morlocks\n",
            "4. Hid in the vast arched cavern\n",
            "\n",
            "correct: Lit another match and retreated to the tunnel\n",
            "\n",
            "difficulty: medium\n",
            "\n",
            "\n",
            "question: What did the narrator observe about the wells?\n",
            "\n",
            "1. They were connected to tall towers\n",
            "2. They had no bottom\n",
            "3. They emitted a flicker in the air\n",
            "4. They were filled with water\n",
            "\n",
            "correct: They emitted a flicker in the air\n",
            "\n",
            "difficulty: hard\n",
            "\n",
            "\n",
            "question: According to the Time Traveller, why is Time regarded as something different?\n",
            "\n",
            "1. Because it is a fourth dimension of Space\n",
            "2. Because it cannot be measured\n",
            "3. Because it is a concept created by humans\n",
            "4. Because it is a fictional idea\n",
            "\n",
            "correct: Because it is a fourth dimension of Space\n",
            "\n",
            "difficulty: hard\n",
            "\n",
            "\n",
            "Tokens Used: 1716\n",
            "\tPrompt Tokens: 1281\n",
            "\tCompletion Tokens: 435\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.0027914999999999997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Experiments"
      ],
      "metadata": {
        "id": "UjpJTzoLHffy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "def get_docs_pdf_exp(path, chunk_size=500, chunk_overlap=0):\n",
        "  \"\"\"\n",
        "  note:\n",
        "    * When chunk_overlap=0, it will try not cut sentences, which is good for out case\n",
        "  \"\"\"\n",
        "\n",
        "  loader = PyPDFLoader(path, extract_images=True)\n",
        "\n",
        "  text_splitter = CharacterTextSplitter(\n",
        "      separator=\"\\n\",\n",
        "      chunk_size=chunk_size,\n",
        "      chunk_overlap=chunk_overlap,\n",
        "      length_function=len,\n",
        "      is_separator_regex=False,\n",
        "  )\n",
        "\n",
        "  # by default it was doing page split\n",
        "  docs = loader.load_and_split(text_splitter=text_splitter)\n",
        "\n",
        "  return docs"
      ],
      "metadata": {
        "id": "3hCmdE-WHohK"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_01 = get_docs_pdf_exp(pdf_path_pdf_test_01)"
      ],
      "metadata": {
        "id": "G2jlbLd6HreC"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index, doc in enumerate(docs_01):\n",
        "  print(f'Doc: {index+1}')\n",
        "  print(doc.page_content)\n",
        "  print(doc.metadata)\n",
        "  print('\\n')"
      ],
      "metadata": {
        "id": "RY3FkwT-HvQi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "452d188f-d007-4d47-db34-2c52b4a1c225"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Doc: 1\n",
            "PDF-T est-01\n",
            "1P D F - T e s t - 0 1\n",
            "It\n",
            "the\n",
            "best of\n",
            ":was\n",
            "times, it\n",
            "the\n",
            "was\n",
            " worst\n",
            "of times, it\n",
            "the a\n",
            "was\n",
            "age\n",
            "of wisdom, it\n",
            "the\n",
            "was\n",
            "age of foolishness...\n",
            "{'source': '/content/drive/MyDrive/datasets/exam_mcq_generator/pdfs/pdf_test_01.pdf', 'page': 0}\n",
            "\n",
            "\n",
            "Doc: 2\n",
            "PDF-T est-01\n",
            "2\n",
            "\"LIVELIFEWITHNO EXCLISES\n",
            "TRAVELWITHNOREGRET\"\n",
            "-OSCAR WILDESintony\n",
            "120\n",
            "ABIEIALUAX\n",
            "AlignHorizontally\n",
            "Left\n",
            "三Center\n",
            "三Right\n",
            "三Justify\n",
            "Align Vertically\n",
            "不Top\n",
            "Middle\n",
            "Bottom\n",
            "{'source': '/content/drive/MyDrive/datasets/exam_mcq_generator/pdfs/pdf_test_01.pdf', 'page': 1}\n",
            "\n",
            "\n",
            "Doc: 3\n",
            "PDF-T est-01\n",
            "3\n",
            "{'source': '/content/drive/MyDrive/datasets/exam_mcq_generator/pdfs/pdf_test_01.pdf', 'page': 2}\n",
            "\n",
            "\n",
            "Doc: 4\n",
            "PDF-T est-01\n",
            "4\n",
            "{'source': '/content/drive/MyDrive/datasets/exam_mcq_generator/pdfs/pdf_test_01.pdf', 'page': 3}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5HSvJCLPJzqE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}