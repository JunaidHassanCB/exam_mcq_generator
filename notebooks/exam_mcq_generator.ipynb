{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Resources"
      ],
      "metadata": {
        "id": "bJ04CPCrZgDQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* https://www.youtube.com/watch?v=ZzgUqFtxgXI\n",
        "* https://www.youtube.com/watch?v=7aBRk_JP-qY\n",
        "* https://learn.deeplearning.ai/langchain-chat-with-your-data/lesson/3/document-splitting"
      ],
      "metadata": {
        "id": "LkiJqtHQZiym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction"
      ],
      "metadata": {
        "id": "m-ikwGBjMI4K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Title: Exam MCQ Generator"
      ],
      "metadata": {
        "id": "mLRXYyYMML6S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Game Plan:\n",
        "\n",
        "*   Divide the document into multiple chuncks and then select chunks at random, pass them to Langchain and ask to make an MCQ out of it"
      ],
      "metadata": {
        "id": "o7UK-p8sMPZK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Installs"
      ],
      "metadata": {
        "id": "bmFi-Hk6Evih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q python-dotenv\n",
        "\n",
        "!pip install -q langchain_experimental\n",
        "!pip install -q langchain\n",
        "\n",
        "!pip install -q openai"
      ],
      "metadata": {
        "id": "u2t8uaVSEwvu"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pydantic"
      ],
      "metadata": {
        "id": "7HVRFDBtRaW_"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "A1x1YGfOE_oS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "pS0ZpqhCFBMR"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Source"
      ],
      "metadata": {
        "id": "Uoi0Wy5cXo_h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q29vd3OyXQka",
        "outputId": "56d4c973-82b6-425d-a278-586d7c5d27cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wizard_in_oz_text_path = '/content/drive/MyDrive/datasets/llm-from-scratch/wizard_in_oz.txt'"
      ],
      "metadata": {
        "id": "Ka2XEvl8XrG1"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_text_file(path):\n",
        "  with open(path, 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "  return text"
      ],
      "metadata": {
        "id": "Ftmzc3K3QW7T"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = read_text_file(wizard_in_oz_text_path)"
      ],
      "metadata": {
        "id": "2XeC5XxUdiEI"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2ET8m79disZ",
        "outputId": "62b2f6c1-d245-41f7-a86a-55546c4f2105"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ï»¿Title: Dorothy and the Wizard in Oz\n",
            "\n",
            "\n",
            "Author: L. Frank Baum\n",
            "\n",
            "Illustrator: John R. Neill\n",
            "\n",
            "Release da\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Env"
      ],
      "metadata": {
        "id": "64daLT8tFOIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env_path = '/content/drive/MyDrive/credentials/data-analytics-demo/.env'"
      ],
      "metadata": {
        "id": "V3RXC1W0djkz"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "load_dotenv(env_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymW18blMFMOM",
        "outputId": "9302d500-3eb2-4b4d-8f01-21b0d423381b"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_PALM_API_KEY = os.environ['GOOGLE_PALM_API_KEY']\n",
        "HUGGINGFACE_API_KEY = os.environ['HUGGINGFACE_API_KEY']\n",
        "OPEN_AI_API_KEY = os.environ['OPEN_AI_API_KEY']\n",
        "\n",
        "# GOOGLE_PALM_API_KEY, HUGGINGFACE_API_KEY, OPEN_AI_API_KEY"
      ],
      "metadata": {
        "id": "Er0qbi8PFNey"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "6vYSSCaaOwTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class MCQModel(BaseModel):\n",
        "  question: str = Field(description=\"This is the question text\")\n",
        "  options: list[str] = Field(description=\"This is a list of multiple choices or options avalible\")\n",
        "  correct_option: str = Field(description=\"This is the correct choice or option\")"
      ],
      "metadata": {
        "id": "Qf3wdSRvDZ6q"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import PydanticOutputParser\n",
        "\n",
        "pydantic_parser = PydanticOutputParser(pydantic_object=MCQModel)\n",
        "\n",
        "format_instructions = pydantic_parser.get_format_instructions()\n",
        "\n",
        "print(format_instructions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UomvYYs3Er4d",
        "outputId": "1e377f8d-0b13-4d68-ddd7-ef416baace93"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"properties\": {\"question\": {\"title\": \"Question\", \"description\": \"This is the question text\", \"type\": \"string\"}, \"options\": {\"title\": \"Options\", \"description\": \"This is a list of multiple choices or options avalible\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}, \"correct_option\": {\"title\": \"Correct Option\", \"description\": \"This is the correct choice or option\", \"type\": \"string\"}}, \"required\": [\"question\", \"options\", \"correct_option\"]}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "langchain_llm = ChatOpenAI(openai_api_key=OPEN_AI_API_KEY, model_name=\"gpt-3.5-turbo-0613\", verbose=False,)"
      ],
      "metadata": {
        "id": "HLQQRe4DebG9"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = CharacterTextSplitter(\n",
        "    separator=\"\\n\",\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        ")"
      ],
      "metadata": {
        "id": "felQ-ng_FZyj"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = text_splitter.create_documents([text])"
      ],
      "metadata": {
        "id": "fSgy5XPkO2Ua"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Total Documents Created: {len(texts)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59jRPe0bPciN",
        "outputId": "50d894ad-b16b-4e69-f205-c4c9db18b436"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Documents Created: 287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = (\n",
        "    \"Text:\"\n",
        "    \"\\n{text}\"\n",
        "    \"\\nGenerate an Multiple Choice Question from this text. Also return the correct option.\"\n",
        "    \"\\nDo not use any outside information\"\n",
        "    \"\\n{format_instructions}\"\n",
        ")"
      ],
      "metadata": {
        "id": "O5feLlNGRRbC"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = ChatPromptTemplate.from_template(prompt)\n",
        "\n",
        "prompt_template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2U1SRNNRxV3",
        "outputId": "c27fe0a3-9dd5-409f-f8c3-6ea11a3ba78c"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['format_instructions', 'text'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['format_instructions', 'text'], template='Text:\\n{text}\\nGenerate an Multiple Choice Question from this text. Also return the correct option.\\nDo not use any outside information\\n{format_instructions}'))])"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain = LLMChain(llm=langchain_llm, prompt=prompt_template, output_key=\"result\")"
      ],
      "metadata": {
        "id": "q6y-XA9ySO3K"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.callbacks import get_openai_callback as get_langchain_openai_callback\n",
        "import random\n",
        "\n",
        "def get_question():\n",
        "  doc_index = random.randint(0, len(texts)-1)\n",
        "\n",
        "  with get_langchain_openai_callback() as cb_langchain:\n",
        "    response = llm_chain.invoke({\"text\": texts[doc_index], \"format_instructions\": format_instructions})\n",
        "\n",
        "  return {'doc_index': doc_index, 'mcq': response['result'], 'cb_langchain': cb_langchain}"
      ],
      "metadata": {
        "id": "tMFoHATzPiG5"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing"
      ],
      "metadata": {
        "id": "45rsHQaGmfaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response_raw = get_question()\n",
        "response_parsed = MCQModel.parse_raw(response_raw['mcq'])"
      ],
      "metadata": {
        "id": "1EbUZdLie2AV"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response_parsed)\n",
        "\n",
        "print('\\n')\n",
        "print(f\"doc_index = {response_raw['doc_index']}\")\n",
        "print('\\ncosting:\\n')\n",
        "print(f\"{response_raw['cb_langchain']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8P_jJpXe4Kd",
        "outputId": "22c68fad-e625-4926-bd16-8becc651cfa2"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question='Who ruled the Land of Oz?' options=['The Princess', 'The Wizard', 'The Witches', 'The Munchkins'] correct_option='The Wizard'\n",
            "\n",
            "\n",
            "doc_index = 218\n",
            "\n",
            "costing:\n",
            "\n",
            "Tokens Used: 538\n",
            "\tPrompt Tokens: 497\n",
            "\tCompletion Tokens: 41\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.0008275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_parsed"
      ],
      "metadata": {
        "id": "JmtPT3naHFt2",
        "outputId": "aa311b6a-540a-4e8d-85e2-e31c1d92a12a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MCQModel(question='Who ruled the Land of Oz?', options=['The Princess', 'The Wizard', 'The Witches', 'The Munchkins'], correct_option='The Wizard')"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pydantic Demo"
      ],
      "metadata": {
        "id": "vJU1KnNYRUIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, EmailStr, validator\n",
        "\n",
        "class User(BaseModel):\n",
        "  name: str\n",
        "  # email: EmailStr\n",
        "  email: str\n",
        "  account_id: int\n",
        "\n",
        "  @validator(\"account_id\")\n",
        "  def validate_account_id(cls, value):\n",
        "    if value<=0:\n",
        "      raise ValueError(f'Account ID cannot be negative: {value}')\n",
        "\n",
        "    return value\n",
        "\n",
        "user = User(name='jack', email='a@b.com', account_id=1234)\n",
        "\n",
        "print(user)\n",
        "print(user.json())\n",
        "print(user.dict())\n",
        "print(user.parse_raw(user.json()))"
      ],
      "metadata": {
        "id": "KHFMUsI0fRll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5692ac35-f8bc-429a-89c9-6bf02fb00d9c"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name='jack' email='a@b.com' account_id=1234\n",
            "{\"name\": \"jack\", \"email\": \"a@b.com\", \"account_id\": 1234}\n",
            "{'name': 'jack', 'email': 'a@b.com', 'account_id': 1234}\n",
            "name='jack' email='a@b.com' account_id=1234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Working Demo"
      ],
      "metadata": {
        "id": "yqGQ313tPiGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts_path = '/content/drive/MyDrive/datasets/exam_mcq_generator/texts'"
      ],
      "metadata": {
        "id": "jkYbAdbrR0gV"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_path_01 = os.path.join(texts_path, '01.txt')\n",
        "text_path_02 = os.path.join(texts_path, '02.txt')\n",
        "text_path_03 = os.path.join(texts_path, '03.txt')\n",
        "text_path_04 = os.path.join(texts_path, '04.txt')\n",
        "text_path_05 = os.path.join(texts_path, '05.txt')"
      ],
      "metadata": {
        "id": "p_oFAcrAP3V6"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_01 = read_text_file(text_path_01)\n",
        "\n",
        "display(text_01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "k9Dq7cpKQLI8",
        "outputId": "f94e8c3e-0603-4993-f700-b1e8262f13ac"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"In the small coastal village of Eldridge Haven, where the briny scent of the ocean mingled with the sweet fragrance of blooming flowers, lived a young woman named Seraphina. Her days were filled with the rhythmic ebb and flow of tide, the gentle whispers of the wind through ancient willows, and the comforting routine of life in a close-knit community. Yet, beneath the surface of tranquil routine lurked an undercurrent of restlessness that stirred within Seraphina's soul, beckoning her toward the unknown.\\n\\nOne fateful evening, as the sun dipped below the horizon, casting a warm palette of pinks and purples across the sky, Seraphina took a solitary stroll along the shore. The rhythmic crashing of the waves seemed to sync with the beating of her heart, echoing the unspoken desire for adventure that tugged at the edges of her consciousness. Little did she know that this serene walk would unravel the fabric of her familiar existence and set her on a path of unforeseen destiny.\\n\\nIn the twilight, Seraphina stumbled upon an ancient artifact half-buried in the sand. Intricately carved and pulsating with an otherworldly glow, the artifact emitted a magnetic energy that drew her closer. Hesitant but undeniably intrigued, she gingerly brushed away the sand, revealing a peculiar map etched into the surface. The map depicted an uncharted archipelago, marked by cryptic symbols and enigmatic landmarks that seemed to defy the laws of geography.\\n\\nWith a surge of determination, Seraphina decided to embark on a journey to unravel the mysteries hidden within the ancient map. Her departure from Eldridge Haven was met with a mixture of concern and anticipation, as the villagers sensed an unspoken destiny weaving its threads around their beloved resident. Equipped with a weathered satchel, a compass, and the shimmering artifact as her guide, Seraphina set sail into the vast unknown.\\n\\nAs her boat cut through the cerulean waters, the winds whispered tales of lost civilizations and forgotten magic. Seraphina encountered mythical creatures, forged alliances with enigmatic beings, and faced trials that tested the limits of her courage and resilience. Along the way, she discovered that the archipelago held the key to a realm suspended between reality and dreamsâa realm where the boundaries of time and space intertwined in a dance of cosmic significance.\\n\\nThe journey, both perilous and enchanting, transformed Seraphina from a curious villager into a guardian of realms, entrusted with the task of restoring balance to the delicate tapestry of existence. Her story echoed through the ages, inspiring generations to come, as the village of Eldridge Haven continued to thrive under the watchful eyes of those who remembered the young woman who dared to venture beyond the shores of familiarity.\\n\\nAnd so, as the sun dipped below the horizon once more, casting a warm palette of pinks and purples across the sky, Eldridge Haven stood as a testament to the enduring power of curiosity, courage, and the uncharted territories that reside within every soul.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_02 = read_text_file(text_path_02)\n",
        "\n",
        "display(text_02)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "kd-xW7XjQRgq",
        "outputId": "52d1a7e4-dbe8-43fc-e001-7e3aac27d4e4"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'In the not-so-distant future, a revolutionary technological marvel known as SynthEra emerged from the laboratories of Quantum Dynamics Innovations, forever altering the landscape of human experience. SynthEra, a groundbreaking neural interface, represented the pinnacle of advancements in neurotechnology, seamlessly blending the digital and biological realms.\\n\\nAt its core, SynthEra was designed to establish a direct and symbiotic connection between the human brain and the vast expanse of digital information. Consisting of a sleek neuro-interface headset adorned with an intricate web of sensors, SynthEra employed advanced neurostimulation algorithms to interpret neural signals, transforming thoughts into actionable commands. The device seamlessly integrated with the user\\'s cognitive functions, creating an immersive and intuitive interface for navigating the digital world.\\n\\nThe possibilities unlocked by SynthEra were nothing short of awe-inspiring. Users could interact with augmented reality overlays projected directly into their field of vision, their thoughts shaping and manipulating the virtual environment around them. Information retrieval became instantaneous as users could access vast databases, analyze complex data sets, and even communicate with others in a purely mental dialogue.\\n\\nThe impact of SynthEra rippled through various sectors, revolutionizing fields such as medicine, education, and entertainment. In healthcare, surgeons utilized the neuro-interface for precision surgeries, with the ability to visualize intricate anatomical structures in real-time. The educational landscape transformed as students engaged in immersive learning experiences, exploring historical events or dissecting virtual organisms with unprecedented detail. The entertainment industry embraced SynthEra to create interactive narratives where users could become protagonists in their own virtual adventures.\\n\\nHowever, with the boundless potential of SynthEra came ethical considerations and societal shifts. Questions arose about privacy, security, and the potential misuse of such intimate access to the human mind. Striking a delicate balance between innovation and responsibility became paramount as policymakers, ethicists, and technologists grappled with the implications of this transformative technology.\\n\\nAs SynthEra became more ubiquitous, a vibrant subculture emerged, dedicated to pushing the boundaries of the neural interface\\'s capabilities. Pioneering \"neuro-artists\" crafted mesmerizing digital landscapes, and \"mind musicians\" composed symphonies that transcended traditional auditory experiences. The intersection of technology and creativity gave rise to a new era of human expression, where the boundaries between the tangible and the virtual blurred.\\n\\nIn the annals of technological history, SynthEra stood as a testament to humanity\\'s relentless pursuit of innovation. It brought forth a future where the mind\\'s potential was harnessed, transcending the limitations of the physical world and ushering in an era where the convergence of biology and technology reshaped the very fabric of human existence.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_03 = read_text_file(text_path_03)\n",
        "\n",
        "display(text_03)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "eUqx7UGmQR5z",
        "outputId": "d9bf9bdb-55f4-4829-f208-a313f6adf04e"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"Deep within the esoteric realm of abstract mathematics, a conundrum known as the Collatz conjecture captivated the minds of scholars and amateurs alike. Born in the mid-20th century from the intellect of German mathematician Lothar Collatz, this seemingly straightforward problem birthed a puzzle that has defied resolution for decades, its elusiveness challenging the very core of mathematical understanding.\\n\\nAt its heart, the Collatz conjecture revolves around the interplay of natural numbers. The rules are deceptively simple: take any positive integer 'n,' if it is even, divide it by 2; if it is odd, triple it and add 1. Repeat this process iteratively, and the conjecture posits that, regardless of the starting value, the sequence will eventually reach the elusive cycle of 4, 2, 1, and from thereon endlessly loop in this enigmatic dance.\\n\\nMathematicians, drawn to the allure of simplicity masking complexity, embarked on a journey to unlock the secrets embedded in the Collatz conjecture. Initial investigations hinted at an apparent inevitability in the convergence towards the conjectured cycle, yet as the numbers surged into the stratosphere, a chaotic unpredictability emerged. The sequence exhibited an erratic behavior, evading discernible patterns and confounding attempts at prediction.\\n\\nThe allure of the Collatz conjecture lies in its accessibility â a puzzle simple enough for amateurs to grasp, yet inscrutable enough to bewilder the most seasoned mathematicians. The simplicity of its formulation belies the depth of the mystery it conceals, inviting a vast array of mathematical minds to lend their insights to the ongoing quest for understanding.\\n\\nAs the mathematical community grappled with the Collatz conjecture, a sense of camaraderie and shared intrigue blossomed. Collaborative efforts spanned continents, facilitated by the interconnectedness of the digital age. Research papers proliferated, each proposing new avenues of exploration, and online forums buzzed with discussions ranging from computational approaches to philosophical musings on the nature of mathematical truth.\\n\\nYet, the Collatz conjecture remained elusive, a testament to the enduring mysteries within the seemingly straightforward realm of number theory. Mathematicians, undeterred by the obstinacy of the problem, continued to delve into its depths, driven by an innate curiosity to unravel the secrets concealed within the dance of numbers.\\n\\nIn the grand tapestry of mathematical inquiry, the Collatz conjecture stood as a testament to the persistent allure of the unknown. Its resolution, if it ever comes, promises not just a solution to a mathematical puzzle, but a deeper understanding of the intricate and unpredictable beauty woven into the fabric of numbers. As the quest continued, mathematicians embraced the uncertainty, for within the pursuit of the unsolved lies the essence of the mathematical spirit â an unyielding quest for knowledge and the boundless exploration of the infinite realms of possibility.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_04 = read_text_file(text_path_04)\n",
        "\n",
        "display(text_04)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "jtn6noomQSQ6",
        "outputId": "f6ac0701-e9e1-406f-f35f-877c7201ff4a"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"In the vast expanse of human linguistic articulation, poetry emerges as an enigmatic manifestation, a convolution of lexical cadence that transcends the conventional confines of mundane discourse. Within the nebulous realms of metaphorical articulation, poets, as lexical alchemists, wield a contrivance of language that begets an ethereal symphony, wherein the elusive shades of human sentiment meander.\\n\\nThe nuanced choreography of syllabic configurations and rhythmic resonances imbues poets with the capacity to metamorphose prosaic verbiage into an intricate mosaic of expressive profundity. In its essence, a meticulously wrought poem becomes a tapestry of allegorical impressions, each epithet and turn of phrase akin to a brushstroke upon the canvas of cognition.\\n\\nThe potency of poetry resides not solely within its articulated lexicon but rather within the interstices of verbal modulations, the intervals of pregnant reticence that implore the discerning reader to tarry and ruminate. It is in these lacunae that the ineffable finds manifestation, where the unuttered specters of human affectivity assume tangible form. The poet, akin to a sagacious navigator, escorts the reader through the labyrinthine corridors of sentiment, proffering a compass to traverse the tumultuous seas of amour, bereavement, elation, and desolation.\\n\\nThe aesthetic allure of poetry lies in its prowess to distill intricate emotions into a paltry ensemble of meticulously chosen lexemes, endowing the abstract with palpability and the elusive with corporeal essence. It is the art of compaction, wherein brevity metamorphoses into a virtuous quality, and each uttered word bears the gravitas of multitudes. Poets wield language with a precision that discloses strata of signification, prompting readers to excise the layers of lyrical veneer and unveil the profound verities beneath.\\n\\nPoetry, in its kaleidoscopic array, manifests in sundry configurations and idioms. From the structured suavity of sonnets to the unbridled cadence of untrammeled verse, every poetic modality proffers a distinctive perspective through which to scrutinize the human milieu. It constitutes a medium where the poet's oration, akin to a nightingale's song at dawn, may soar to unparalleled altitudes or whisper secrets that reverberate in the placid recesses of the soul.\\n\\nBeyond its aesthetic inclination, poetry transmutes into a bridge connecting cultures and epochs, a testament to the ubiquity of the human experiential spectrum. It transcends linguistic demarcations, beckoning readers to navigate the intricate tapestry of disparate voices that reverberate through temporal epochs. Through the medium of poetry, the echoes of antiquarian civilizations, the minstrelsy of troubadours, and the contemporaneous musings of modern versifiers coalesce in a perennial colloquy that transcends the constraints of chronological and spatial coordinates.\\n\\nIn a world rife with the ceaseless tumult of quotidian existence, poetry assumes the mantle of a sanctum, a serene oasis where introspection and contemplation find reprieve. It serves as an emollient for the psyche, offering refuge for those compelled to distill meaning from a cacophonous milieu or to eulogize the aesthetic splendors that proliferate. The poet's quill assumes the guise of a wand, weaving incantations that transport readers to domains where emotions course like rivers and imagination takes wing.\\n\\nIn the expansive canvas of human enunciation, poetry stands as an incandescent filament, forging connections betwixt disparate hearts and intellects. It constitutes a testament to the indomitable tenacity of language, the boundless potentiality of words to evoke, inspire, and transcend. As long as human hearts pulsate and cerebra ponder, poetry will endureâan everlasting testimonial to the exquisite choreography of language and the profound allure embedded in the delicate equipoise of verbiage.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_05 = read_text_file(text_path_05)\n",
        "\n",
        "display(text_05)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "deJ35F9NQoo7",
        "outputId": "5bb60971-20dc-4fa9-c75b-7ab07648f84f"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"The history of Large Language Models (LLMs) is a fascinating journey that spans the intersection of artificial intelligence, natural language processing, and machine learning. The roots of LLMs can be traced back to the early endeavors in computational linguistics, where researchers sought to develop systems capable of understanding and generating human-like language.\\n\\nThe seeds of LLMs were sown in the mid-20th century, with early attempts at computer-based language translation. The Georgetown-IBM experiment in 1954 marked a pioneering effort, utilizing an early computer to translate Russian sentences into English. However, these early endeavors were constrained by the limited computational power of the time, and the results fell short of achieving true linguistic nuance.\\n\\nAs computational capabilities burgeoned in the latter half of the 20th century, researchers delved into more sophisticated approaches to natural language processing. Rule-based systems emerged, relying on predefined linguistic rules to analyze and generate human language. Despite incremental advancements, these rule-based systems struggled with the inherent ambiguity and complexity of language.\\n\\nThe advent of statistical approaches in the late 20th century heralded a paradigm shift in natural language processing. Machine learning algorithms, particularly those rooted in statistical modeling, began to outperform rule-based systems. Statistical language models, often based on n-gram models, gained traction by discerning patterns and probabilities from vast corpora of textual data.\\n\\nThe watershed moment in the evolution of LLMs arrived with the rise of neural networks and deep learning in the 21st century. The introduction of recurrent neural networks (RNNs) and later, long short-term memory networks (LSTMs), enabled models to capture contextual dependencies and sequence information effectively. These architectures paved the way for more sophisticated language models that could understand and generate coherent, contextually relevant text.\\n\\nHowever, the true breakthrough came with the advent of transformer architectures. The transformer model, introduced by Vaswani et al. in 2017, revolutionized natural language processing. Its self-attention mechanism allowed models to consider contextual information across the entire input sequence, enabling unparalleled performance in tasks like language translation, text summarization, and sentiment analysis.\\n\\nThe Transformer architecture laid the groundwork for the development of large-scale language models, such as OpenAI's GPT (Generative Pre-trained Transformer) series. GPT-3, introduced in 2020, marked a watershed moment in the field. With a staggering 175 billion parameters, GPT-3 demonstrated an unprecedented capacity to understand and generate diverse and contextually coherent text.\\n\\nThe evolution of LLMs has not been without ethical and societal considerations. The sheer scale and complexity of these models raise concerns about bias, accountability, and the environmental impact of their training processes. Researchers and developers continue to grapple with these challenges, emphasizing the need for responsible AI practices.\\n\\nAs of the present, LLMs continue to shape the landscape of natural language processing and artificial intelligence. Ongoing research focuses on refining these models, addressing ethical concerns, and exploring novel applications that leverage the profound capabilities of large language models. The history of LLMs is a testament to the relentless pursuit of unlocking the mysteries of human language through the lens of computational ingenuity.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tX4BzLEoQ79M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}